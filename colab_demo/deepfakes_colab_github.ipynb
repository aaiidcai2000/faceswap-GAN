{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepfakes_colab_github.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XZ6yo8sQLbn",
        "outputId": "fc86bde6-98b1-4807-bdcc-9c4c85b1cc8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nP8c4Y9QgNu",
        "outputId": "17fd7f2a-8fca-4138-8364-5102e254a767",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls /content/drive/MyDrive/"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " faceswap-GAN\t\t\t\t      宋楚瑜.mp4\n",
            " glenmusic-backup_from20180707-20190801.zip  \"習近平.CUT.00'34-02'27.mp4\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wei_exlXQogu"
      },
      "source": [
        "source_video = /content/drive/MyDrive/宋楚瑜.mp4\n",
        "target_vidoe = /content/drive/MyDrive/習近平.CUT.00'34-02'27.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy2oTGygjSdq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e147809d-94e4-4392-dc6a-b00208b6aff3"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZXY2GsMdt3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f0a4b42-ef6d-4f71-c709-86f87144dc98"
      },
      "source": [
        "!git clone --single-branch --branch r1.0 https://github.com/deepfakes/faceswap.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'faceswap'...\n",
            "remote: Enumerating objects: 7362, done.\u001b[K\n",
            "remote: Total 7362 (delta 0), reused 0 (delta 0), pack-reused 7362\u001b[K\n",
            "Receiving objects: 100% (7362/7362), 193.97 MiB | 18.56 MiB/s, done.\n",
            "Resolving deltas: 100% (5070/5070), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfDRa8tGeFCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44bce2d6-3f33-4340-f9c8-de13f1c2c599"
      },
      "source": [
        "%cd faceswap/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/faceswap/faceswap\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K52YSCrseIA3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05bc342f-9788-4379-fef8-241ebef86117"
      },
      "source": [
        "!python setup.py"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO   \u001b[0m Running as Root/Admin\n",
            "\u001b[32mINFO   \u001b[0m The tool provides tips for installation\r\n",
            "        and installs required python packages\n",
            "\u001b[32mINFO   \u001b[0m Setup in Linux 4.19.112+\n",
            "\u001b[32mINFO   \u001b[0m Installed Python: 3.6.9 64bit\n",
            "\u001b[32mINFO   \u001b[0m Encoding: UTF-8\n",
            "\u001b[32mINFO   \u001b[0m Upgrading pip...\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 4.2MB/s \n",
            "\u001b[?25h\u001b[32mINFO   \u001b[0m Installed pip: 19.3.1\n",
            "\u001b[32mINFO   \u001b[0m AMD Support: AMD GPU support is currently limited.\n",
            "        Nvidia Users MUST answer 'no' to this option.\n",
            "Enable AMD Support? [y/N] y\n",
            "\u001b[32mINFO   \u001b[0m AMD Support Enabled\n",
            "\u001b[32mINFO   \u001b[0m Faceswap config written to: /content/faceswap/faceswap/config/.faceswap\n",
            "Please ensure your System Dependencies are met. Continue? [y/N] y\n",
            "\u001b[32mINFO   \u001b[0m Installing Required Python Packages. This may take some time...\n",
            "\u001b[32mINFO   \u001b[0m Installing tqdm>=4.42\n",
            "\u001b[K     |████████████████████████████████| 69 kB 5.2 MB/s \n",
            "\u001b[?25h\u001b[32mINFO   \u001b[0m Installing psutil>=5.7.0\n",
            "\u001b[K     |████████████████████████████████| 465 kB 4.1 MB/s \n",
            "\u001b[?25h  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[32mINFO   \u001b[0m Installing pillow>=7.0.0\n",
            "\u001b[32mINFO   \u001b[0m Installing toposort==1.5\n",
            "\u001b[32mINFO   \u001b[0m Installing fastcluster==1.1.26\n",
            "\u001b[K     |████████████████████████████████| 154 kB 4.1 MB/s \n",
            "\u001b[?25h\u001b[32mINFO   \u001b[0m Installing imageio>=2.8.0\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 4.3 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h\u001b[32mINFO   \u001b[0m Installing imageio-ffmpeg>=0.4.2\n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 67.0 MB/s \n",
            "\u001b[?25h\u001b[32mINFO   \u001b[0m Installing ffmpy==0.2.3\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[32mINFO   \u001b[0m Installing Keras==2.2.4\n",
            "\u001b[K     |████████████████████████████████| 312 kB 4.2 MB/s \n",
            "\u001b[?25h\u001b[32mINFO   \u001b[0m Installing plaidml-keras==0.6.4\n",
            "\u001b[K     |████████████████████████████████| 312 kB 5.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 22.0 MB 63.9 MB/s \n",
            "\u001b[?25h\u001b[32mINFO   \u001b[0m Installing plaidml==0.6.4\n",
            "\u001b[K     |████████████████████████████████| 32.1 MB 1.4 MB/s \n",
            "\u001b[?25h\u001b[32mINFO   \u001b[0m Installing git+https://github.com/deepfakes/nvidia-ml-py3.git\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[32mINFO   \u001b[0m All python3 dependencies are met.\n",
            "        You are good to go.\n",
            "        \n",
            "        Enter:  'python faceswap.py -h' to see the options\n",
            "                'python faceswap.py gui' to launch the GUI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12af5iKGeKW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf99707a-cd7e-420d-cd24-8f93f0b00733"
      },
      "source": [
        "\n",
        "!python faceswap.py "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting Faceswap backend to AMD\n",
            "(Namespace(func=<function _bad_args at 0x7fd9b6b5a950>),)\n",
            "usage: faceswap.py [-h] {extract,train,convert,gui} ...\n",
            "\n",
            "positional arguments:\n",
            "  {extract,train,convert,gui}\n",
            "    extract             Extract the faces from pictures\n",
            "    train               This command trains the model for the two faces A and\n",
            "                        B\n",
            "    convert             Convert a source image to a new one with the face\n",
            "                        swapped\n",
            "    gui                 Launch the Faceswap Graphical User Interface\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNABfP_HekJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b7d99de-7892-429f-eee9-4743eaa63d5b"
      },
      "source": [
        "!python faceswap.py extract -h"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting Faceswap backend to AMD\n",
            "usage: faceswap.py extract [-h] [-C CONFIGFILE]\n",
            "                           [-L {INFO,VERBOSE,DEBUG,TRACE}] [-LF LOGFILE] -i\n",
            "                           INPUT_DIR -o OUTPUT_DIR [-al ALIGNMENTS_PATH]\n",
            "                           [-D {cv2-dnn,mtcnn,s3fd}] [-A {cv2-dnn,fan}]\n",
            "                           [-M {unet-dfl,vgg-clear,vgg-obstructed} [{unet-dfl,vgg-clear,vgg-obstructed} ...]]\n",
            "                           [-nm {none,clahe,hist,mean}] [-r ROTATE_IMAGES]\n",
            "                           [-min MIN_SIZE] [-n NFILTER [NFILTER ...]]\n",
            "                           [-f FILTER [FILTER ...]] [-l REF_THRESHOLD]\n",
            "                           [-een EXTRACT_EVERY_N] [-sz SIZE]\n",
            "                           [-si SAVE_INTERVAL] [-dl] [-s] [-sf] [-ssf]\n",
            "\n",
            "Extract the faces from pictures\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -C CONFIGFILE, --configfile CONFIGFILE\n",
            "                        Optionally overide the saved config with the path to a\n",
            "                        custom config file.\n",
            "  -L {INFO,VERBOSE,DEBUG,TRACE}, --loglevel {INFO,VERBOSE,DEBUG,TRACE}\n",
            "                        Log level. Stick with INFO or VERBOSE unless you need\n",
            "                        to file an error report. Be careful with TRACE as it\n",
            "                        will generate a lot of data\n",
            "  -LF LOGFILE, --logfile LOGFILE\n",
            "                        Path to store the logfile. Leave blank to store in the\n",
            "                        faceswap folder\n",
            "  -i INPUT_DIR, --input-dir INPUT_DIR\n",
            "                        Input directory or video. Either a directory\n",
            "                        containing the image files you wish to process or path\n",
            "                        to a video file. NB: This should be the source\n",
            "                        video/frames NOT the source faces.\n",
            "  -o OUTPUT_DIR, --output-dir OUTPUT_DIR\n",
            "                        Output directory. This is where the converted files\n",
            "                        will be saved.\n",
            "  -al ALIGNMENTS_PATH, --alignments ALIGNMENTS_PATH\n",
            "                        Optional path to an alignments file. Leave blank if\n",
            "                        the alignments file is at the default location.\n",
            "  -D {cv2-dnn,mtcnn,s3fd}, --detector {cv2-dnn,mtcnn,s3fd}\n",
            "                        Detector to use. Some of these have configurable\n",
            "                        settings in '/config/extract.ini' or 'Settings >\n",
            "                        Configure Extract 'Plugins':\n",
            "                          - cv2-dnn: A CPU only extractor which is the least\n",
            "                            reliable and least resource intensive. Use this if\n",
            "                            not using a GPU and time is important.\n",
            "                          - mtcnn: Good detector. Fast on CPU, faster on GPU.\n",
            "                            Uses fewer resources than other GPU detectors but\n",
            "                            can often return more false positives.\n",
            "                          - s3fd: Best detector. Fast on GPU, slow on CPU. Can\n",
            "                            detect more faces and fewer false positives than\n",
            "                            other GPU detectors, but is a lot more resource\n",
            "                            intensive.\n",
            "  -A {cv2-dnn,fan}, --aligner {cv2-dnn,fan}\n",
            "                        Aligner to use.\n",
            "                          - cv2-dnn: A CPU only landmark detector. Faster,\n",
            "                            less resource intensive, but less accurate. Only\n",
            "                            use this if not using a GPU and time is important.\n",
            "                          - fan: Best aligner. Fast on GPU, slow on CPU.\n",
            "  -M {unet-dfl,vgg-clear,vgg-obstructed} [{unet-dfl,vgg-clear,vgg-obstructed} ...], --masker {unet-dfl,vgg-clear,vgg-obstructed} [{unet-dfl,vgg-clear,vgg-obstructed} ...]\n",
            "                        Additional Masker(s) to use. The masks generated here\n",
            "                        will all take up GPU RAM. You can select none, one or\n",
            "                        multiple masks, but the extraction may take longer the\n",
            "                        more you select. NB: The Extended and Components\n",
            "                        (landmark based) masks are automatically generated on\n",
            "                        extraction.\n",
            "                          - vgg-clear: Mask designed to provide smart\n",
            "                            segmentation of mostly frontal faces clear of\n",
            "                            obstructions. Profile faces and obstructions may\n",
            "                            result in sub-par performance.\n",
            "                          - vgg-obstructed: Mask designed to provide smart\n",
            "                            segmentation of mostly frontal faces. The mask\n",
            "                            model has been specifically trained to recognize\n",
            "                            some facial obstructions (hands and eyeglasses).\n",
            "                            Profile faces may result in sub-par performance.\n",
            "                          - unet-dfl: Mask designed to provide smart\n",
            "                            segmentation of mostly frontal faces. The mask\n",
            "                            model has been trained by community members and\n",
            "                            will need testing for further description. Profile\n",
            "                            faces may result in sub-par performance.\n",
            "                        The auto generated masks are as follows:\n",
            "                          - components: Mask designed to provide facial\n",
            "                            segmentation based on the positioning of landmark\n",
            "                            locations. A convex hull is constructed around the\n",
            "                            exterior of the landmarks to create a mask.\n",
            "                          - extended: Mask designed to provide facial\n",
            "                            segmentation based on the positioning of landmark\n",
            "                            locations. A convex hull is constructed around the\n",
            "                            exterior of the landmarks and the mask is extended\n",
            "                            upwards onto the forehead.\n",
            "                        (eg: `-M unet-dfl vgg-clear`, `--masker vgg-\n",
            "                        obstructed`)\n",
            "  -nm {none,clahe,hist,mean}, --normalization {none,clahe,hist,mean}\n",
            "                        Performing normalization can help the aligner better\n",
            "                        align faces with difficult lighting conditions at an\n",
            "                        extraction speed cost. Different methods will yield\n",
            "                        different results on different sets. NB: This does not\n",
            "                        impact the output face, just the input to the aligner.\n",
            "                          - none: Don't perform normalization on the face.\n",
            "                          - clahe: Perform Contrast Limited Adaptive Histogram\n",
            "                            Equalization on the face.\n",
            "                          - hist: Equalize the histograms on the RGB channels.\n",
            "                          - mean: Normalize the face colors to the mean.\n",
            "  -r ROTATE_IMAGES, --rotate-images ROTATE_IMAGES\n",
            "                        If a face isn't found, rotate the images to try to\n",
            "                        find a face. Can find more faces at the cost of\n",
            "                        extraction speed. Pass in a single number to use\n",
            "                        increments of that size up to 360, or pass in a list\n",
            "                        of numbers to enumerate exactly what angles to check.\n",
            "  -min MIN_SIZE, --min-size MIN_SIZE\n",
            "                        Filters out faces detected below this size. Length, in\n",
            "                        pixels across the diagonal of the bounding box. Set to\n",
            "                        0 for off\n",
            "  -n NFILTER [NFILTER ...], --nfilter NFILTER [NFILTER ...]\n",
            "                        Optionally filter out people who you do not wish to\n",
            "                        process by passing in an image of that person. Should\n",
            "                        be a front portrait with a single person in the image.\n",
            "                        Multiple images can be added space separated. NB:\n",
            "                        Using face filter will significantly decrease\n",
            "                        extraction speed and its accuracy cannot be\n",
            "                        guaranteed.\n",
            "  -f FILTER [FILTER ...], --filter FILTER [FILTER ...]\n",
            "                        Optionally select people you wish to process by\n",
            "                        passing in an image of that person. Should be a front\n",
            "                        portrait with a single person in the image. Multiple\n",
            "                        images can be added space separated. NB: Using face\n",
            "                        filter will significantly decrease extraction speed\n",
            "                        and its accuracy cannot be guaranteed.\n",
            "  -l REF_THRESHOLD, --ref_threshold REF_THRESHOLD\n",
            "                        For use with the optional nfilter/filter files.\n",
            "                        Threshold for positive face recognition. Lower values\n",
            "                        are stricter. NB: Using face filter will significantly\n",
            "                        decrease extraction speed and its accuracy cannot be\n",
            "                        guaranteed.\n",
            "  -een EXTRACT_EVERY_N, --extract-every-n EXTRACT_EVERY_N\n",
            "                        Extract every 'nth' frame. This option will skip\n",
            "                        frames when extracting faces. For example a value of 1\n",
            "                        will extract faces from every frame, a value of 10\n",
            "                        will extract faces from every 10th frame.\n",
            "  -sz SIZE, --size SIZE\n",
            "                        The output size of extracted faces. Make sure that the\n",
            "                        model you intend to train supports your required size.\n",
            "                        This will only need to be changed for hi-res models.\n",
            "  -si SAVE_INTERVAL, --save-interval SAVE_INTERVAL\n",
            "                        Automatically save the alignments file after a set\n",
            "                        amount of frames. By default the alignments file is\n",
            "                        only saved at the end of the extraction process. NB:\n",
            "                        If extracting in 2 passes then the alignments file\n",
            "                        will only start to be saved out during the second\n",
            "                        pass. WARNING: Don't interrupt the script when writing\n",
            "                        the file because it might get corrupted. Set to 0 to\n",
            "                        turn off\n",
            "  -dl, --debug-landmarks\n",
            "                        Draw landmarks on the ouput faces for debugging\n",
            "                        purposes.\n",
            "  -s, --skip-existing   Skips frames that have already been extracted and\n",
            "                        exist in the alignments file\n",
            "  -sf, --skip-existing-faces\n",
            "                        Skip frames that already have detected faces in the\n",
            "                        alignments file\n",
            "  -ssf, --skip-saving-faces\n",
            "                        Skip saving out the face images\n",
            "\n",
            "Questions and feedback: https://faceswap.dev/forum\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSiJcbfljuhD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e56c9bd-2ce6-407b-b905-ab0e28a8bb6d"
      },
      "source": [
        "!python faceswap.py extract -i /content/drive/MyDrive/宋楚瑜.mp4 -o extract_video "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting Faceswap backend to AMD\n",
            "12/08/2020 07:31:31 INFO     Log level set to: INFO\n",
            "12/08/2020 07:31:32 INFO     Setting up for PlaidML\n",
            "12/08/2020 07:31:32 INFO     Setting GPU to largest available supported device. If you want to override this selection, run `plaidml-setup` from the command line.\n",
            "12/08/2020 07:31:32 INFO     Using GPU: ['opencl_nvidia_tesla_k80.0', 'opencl_nvidia_tesla_k80.0']\n",
            "12/08/2020 07:31:32 INFO     Successfully set up for PlaidML\n",
            "12/08/2020 07:31:38 INFO     Output Directory: /content/faceswap/faceswap/extract_video\n",
            "12/08/2020 07:31:43 INFO     Loading Detect from S3Fd plugin...\n",
            "Using plaidml.keras.backend backend.\n",
            "12/08/2020 07:31:44 INFO     Downloading model: 's3fd_keras' from: https://github.com/deepfakes-models/faceswap-models/releases/download/v1.11.1/s3fd_keras_v1.zip\n",
            "Downloading: 100% 11.1M/11.1M [00:01<00:00, 6.13MB/s]\n",
            "12/08/2020 07:31:47 INFO     Extracting: 's3fd_keras'\n",
            "Decompressing: 100% 85.9M/85.9M [00:00<00:00, 104MB/s] \n",
            "12/08/2020 07:31:48 INFO     Loading Align from Fan plugin...\n",
            "12/08/2020 07:31:48 INFO     Downloading model: 'face-alignment-network_2d4_keras' from: https://github.com/deepfakes-models/faceswap-models/releases/download/v1.9.1/face-alignment-network_2d4_keras_v1.zip\n",
            "Downloading: 100% 84.6M/84.6M [00:06<00:00, 13.5MB/s]\n",
            "12/08/2020 07:31:55 INFO     Extracting: 'face-alignment-network_2d4_keras'\n",
            "Decompressing: 100% 92.9M/92.9M [00:01<00:00, 67.9MB/s]\n",
            "12/08/2020 07:31:57 INFO     Loading Mask from Components plugin...\n",
            "12/08/2020 07:31:57 INFO     Loading Mask from Extended plugin...\n",
            "12/08/2020 07:31:57 INFO     Starting, this may take a while...\n",
            "12/08/2020 07:31:57 INFO     Initializing S3FD (Detect)...\n",
            "12/08/2020 07:31:57 INFO     Opening device \"opencl_nvidia_tesla_k80.0\"\n",
            "12/08/2020 07:32:01 INFO     Initialized S3FD (Detect) with batchsize of 4\n",
            "Running pass 1 of 4: Detect:  11% 2041/17970 [12:39<1:37:30,  2.72it/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgUW7qjtLifa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "da1c0867-52dc-45d5-dbec-237222e2bbf6"
      },
      "source": [
        "!python faceswap.py extract -i /content/drive/MyDrive/習近平.CUT.00'34-02'27.mp4 -o extract_video2 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting Faceswap backend to NVIDIA\n",
            "04/27/2020 05:49:06 INFO     Log level set to: INFO\n",
            "04/27/2020 05:49:11 INFO     Output Directory: /content/faceswap/extract_video2\n",
            "04/27/2020 05:49:11 INFO     Loading Detect from S3Fd plugin...\n",
            "Using TensorFlow backend.\n",
            "04/27/2020 05:49:11 INFO     Loading Align from Fan plugin...\n",
            "04/27/2020 05:49:11 INFO     Loading Mask from Components plugin...\n",
            "04/27/2020 05:49:11 INFO     Loading Mask from Extended plugin...\n",
            "04/27/2020 05:49:12 INFO     Starting, this may take a while...\n",
            "04/27/2020 05:49:12 INFO     Initializing S3FD (Detect)...\n",
            "04/27/2020 05:49:16 INFO     Initialized S3FD (Detect) with batchsize of 4\n",
            "04/27/2020 05:49:16 INFO     Initializing FAN (Align)...\n",
            "04/27/2020 05:49:39 INFO     Initialized FAN (Align) with batchsize of 12\n",
            "04/27/2020 05:49:39 INFO     Initializing Components (Mask)...\n",
            "04/27/2020 05:49:39 INFO     Initialized Components (Mask) with batchsize of 1\n",
            "04/27/2020 05:49:39 INFO     Initializing Extended (Mask)...\n",
            "04/27/2020 05:49:39 INFO     Initialized Extended (Mask) with batchsize of 1\n",
            "Running pass 1 of 1: Extraction: 100% 6755/6755 [32:43<00:00,  3.44it/s]\n",
            "04/27/2020 06:22:23 INFO     Writing alignments to: '/content/faceswap/obama_alignments.fsa'\n",
            "04/27/2020 06:22:25 INFO     -------------------------\n",
            "04/27/2020 06:22:25 INFO     Images found:        6755\n",
            "04/27/2020 06:22:25 INFO     Faces detected:      27062\n",
            "04/27/2020 06:22:25 INFO     -------------------------\n",
            "04/27/2020 06:22:25 INFO     Note:\n",
            "04/27/2020 06:22:25 INFO     Multiple faces were detected in one or more pictures.\n",
            "04/27/2020 06:22:25 INFO     Double check your results.\n",
            "04/27/2020 06:22:25 INFO     -------------------------\n",
            "04/27/2020 06:22:25 INFO     Process Succesfully Completed. Shutting Down...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8L4SaVqLmcP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "5ba4f17f-a1f9-4d59-8590-665fc1a135eb"
      },
      "source": [
        "!python faceswap.py train -A extract_video -B extract_video2 -m Model_data_new_videos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting Faceswap backend to NVIDIA\n",
            "04/27/2020 06:31:33 INFO     Log level set to: INFO\n",
            "Using TensorFlow backend.\n",
            "04/27/2020 06:31:36 INFO     Model A Directory: /content/faceswap/extract_video\n",
            "04/27/2020 06:31:36 INFO     Model B Directory: /content/faceswap/extract_video2\n",
            "04/27/2020 06:31:36 INFO     Training data directory: /content/faceswap/Model_data_new_videos\n",
            "04/27/2020 06:31:36 INFO     ===================================================\n",
            "04/27/2020 06:31:36 INFO       Starting\n",
            "04/27/2020 06:31:36 INFO       Press 'ENTER' to save and quit\n",
            "04/27/2020 06:31:36 INFO       Press 'S' to save model weights immediately\n",
            "04/27/2020 06:31:36 INFO     ===================================================\n",
            "04/27/2020 06:31:37 INFO     Loading data, this may take a while...\n",
            "04/27/2020 06:31:37 INFO     Loading Model from Original plugin...\n",
            "04/27/2020 06:31:37 INFO     No existing state file found. Generating.\n",
            "04/27/2020 06:31:38 INFO     Creating new 'original' model in folder: '/content/faceswap/Model_data_new_videos'\n",
            "04/27/2020 06:31:38 INFO     Loading Trainer from Original plugin...\n",
            "04/27/2020 06:31:40 INFO     Enabled TensorBoard Logging\n",
            "[06:31:51] [#00001] Loss A: 0.17465, Loss B: 0.24960\n",
            "04/27/2020 06:31:51 INFO     Backing up models...\n",
            "04/27/2020 06:31:52 INFO     [Saved models] - Average since last save: face_loss_A: 0.17465, face_loss_B: 0.24960\n",
            "[06:33:11] [#00101] Loss A: 0.11991, Loss B: 0.11955\n",
            "04/27/2020 06:33:11 INFO     Backing up models...\n",
            "04/27/2020 06:33:12 INFO     [Saved models] - Average since last save: face_loss_A: 0.14467, face_loss_B: 0.16751\n",
            "[06:34:31] [#00201] Loss A: 0.08893, Loss B: 0.08733\n",
            "04/27/2020 06:34:31 INFO     Backing up models...\n",
            "04/27/2020 06:34:32 INFO     [Saved models] - Average since last save: face_loss_A: 0.10509, face_loss_B: 0.11226\n",
            "[06:35:53] [#00301] Loss A: 0.11696, Loss B: 0.10822\n",
            "04/27/2020 06:35:53 INFO     Backing up models...\n",
            "04/27/2020 06:35:54 INFO     [Saved models] - Average since last save: face_loss_A: 0.08696, face_loss_B: 0.09015\n",
            "[06:36:59] [#00382] Loss A: 0.07453, Loss B: 0.0783804/27/2020 06:36:59 INFO     Exit requested! The trainer will complete its current cycle, save the models and quit (This can take a couple of minutes depending on your training speed). If you want to kill it now, press Ctrl + c\n",
            "[06:36:59] [#00383] Loss A: 0.08931, Loss B: 0.07343\n",
            "04/27/2020 06:36:59 INFO     Backing up models...\n",
            "04/27/2020 06:37:00 INFO     [Saved models] - Average since last save: face_loss_A: 0.07676, face_loss_B: 0.07537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lTmjTUdVW0v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "b1bd305c-2b92-419e-f315-4dae93a05c2c"
      },
      "source": [
        "!python faceswap.py convert -i video1.mp4 -o outpute_dir_video -m \"/content/faceswap/Model_data_new_videos\" -w ffmpeg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting Faceswap backend to NVIDIA\n",
            "04/27/2020 07:26:09 INFO     Log level set to: INFO\n",
            "Using TensorFlow backend.\n",
            "04/27/2020 07:26:12 INFO     Reading alignments from: '/content/faceswap/pual_alignments.fsa'\n",
            "04/27/2020 07:26:14 INFO     Loading Writer from Ffmpeg plugin...\n",
            "04/27/2020 07:26:14 INFO     Loading Model from Original plugin...\n",
            "04/27/2020 07:26:14 INFO     Using configuration saved in state file\n",
            "04/27/2020 07:26:32 INFO     Loaded model from disk: '/content/faceswap/Model_data_new_videos'\n",
            "04/27/2020 07:26:32 INFO     Loading Mask from Box_Blend plugin...\n",
            "04/27/2020 07:26:32 INFO     Loading Mask from Mask_Blend plugin...\n",
            "04/27/2020 07:26:32 INFO     Loading Color from Avg_Color plugin...\n",
            "04/27/2020 07:26:38 INFO     Outputting to: '/content/faceswap/outpute_dir_video/pual_converted.mp4'\n",
            "04/27/2020 07:26:39 WARNING  IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=8, resizing from (450, 360) to (456, 360) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
            "Converting: 100% 44280/44280 [21:36<00:00, 34.15it/s]\n",
            "04/27/2020 07:47:51 INFO     Muxing Audio...\n",
            "04/27/2020 07:47:52 INFO     -------------------------\n",
            "04/27/2020 07:47:52 INFO     Images found:        44280\n",
            "04/27/2020 07:47:52 INFO     Faces detected:      80935\n",
            "04/27/2020 07:47:52 INFO     -------------------------\n",
            "04/27/2020 07:47:52 INFO     Note:\n",
            "04/27/2020 07:47:52 INFO     Multiple faces were detected in one or more pictures.\n",
            "04/27/2020 07:47:52 INFO     Double check your results.\n",
            "04/27/2020 07:47:52 INFO     -------------------------\n",
            "04/27/2020 07:47:52 INFO     Process Succesfully Completed. Shutting Down...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}